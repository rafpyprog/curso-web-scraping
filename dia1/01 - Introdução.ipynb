{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Web Scraping com Python\n",
    "<img src=\"https://inferir.com.br/wp-content/uploads/Banner-Web-Scraping.jpg\">\n",
    "\n",
    "## Introdução\n",
    "\n",
    "### O que é Web Scraping ?\n",
    "\n",
    "<p style=\"text-align: center; font-size: large\">\n",
    "Web Scraping, ou raspagem de dados, consiste em um processo que se utiliza de técnicas de programação para a coleta automatizada de dados provenientes de uma página da web.\n",
    "</p>\n",
    "\n",
    "O objetivo do Web Scraping é a **extração de grandes volumes de dados não estruturados**, normalmente em formato HTML, de serviços ou aplicativos que não oferecem uma interface de programação padrão(API), **estruturando estes dados** para que possam ser armazenados em bancos de dados ou em formatos padrão como CSV, XML ou JSON.\n",
    "\n",
    "<img src=\"img/dados-nao-estruturados.png\">\n",
    "\n",
    "Neste processo, um software denominado **scraper** simula a interação realizada entre um browser\n",
    "operado por um humano e o Web Site."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraper\n",
    "\n",
    "Scraper é um software que simula a interação realizada entre um browser operado por um humano e um Web Site. Possui 3 funções básicas:\n",
    "\n",
    "1. Acesso ao Web Site\n",
    "2. Parsing e Extração de conteúdo\n",
    "3. Estruturação dos resultados\n",
    "\n",
    "\n",
    "#### Procolo HTTP\n",
    "\n",
    "A comunicação entre o browser (cliente) e o web site (servidor) é realizada através de um protocolo padrão chamado **[HTTP](https://pt.wikipedia.org/wiki/Hypertext_Transfer_Protocol)** (Hypertext Transfer Protocol). Ao longo do curso aprenderemos a realizar esta interação cliente-servidor utilizando Python para raspar dados de interesse.\n",
    "\n",
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 50%; float: left;\">\n",
    "        <center><h3>Requests</h3></center>\n",
    "        <img style=\"width: 100%;\" src=\"https://i0.wp.com/blogs.innovationm.com/wp-content/uploads/2016/10/HTTP-Protocol.png?fit=624%2C248\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <center><h3>Headers</h3></center>\n",
    "        <img style=\"width: 50%;\" src=\"https://mdn.mozillademos.org/files/13687/HTTP_Request.png\">\n",
    "    </div>\n",
    "    </div>\n",
    "\n",
    "#### Desenvolvendo um Scraper - 6 Etapas\n",
    "\n",
    "##### Identificar\n",
    "No primeiro passo do processo de desenvolvimento de um scraper precisamos entender qual é a estrutura das páginas que queremos raspar e traçar um plano para extrair tudo que precisamos.\n",
    "\n",
    "##### Navegar\n",
    "Precisamos entender como localizar o dado que queremos extrair dentro do HTML da página, para isto utilizaremos o Dev Tools.\n",
    "\n",
    "O Dev Tools é conjunto de ferramentas integradas ao browser construı́das para facilitar o desenvolvimento de Web Sites. Permite analisar o código, o tráfego de rede e a performance de uma página. É a principal ferramenta de apoio ao desenvolvimento de ***Scrapers***.\n",
    "<br><br>\n",
    "<center>\n",
    "<img style=\"width: 10%;\" src =\"https://cdn.instructables.com/FE1/3CR2/GV0KXNWV/FE13CR2GV0KXNWV.LARGE.jpg\">\n",
    "</center>\n",
    "\n",
    "##### Replicar\n",
    "\n",
    "Neste passo é importante compreender as várias requisições HTTP\n",
    "que a página está realizando para trazer o conteúdo até você,\n",
    "assim poderemos replicar as requisições com nosso Scraper.\n",
    "Utilizaremos a aba Network do Dev Tools para este trabalho.\n",
    "\n",
    "#####  Parsear\n",
    "\n",
    "O anglicismo parsear vem do verbo to parse, que quer dizer algo como analisar ou estudar, mas que, no contexto do Web Scraping, significa extrair os dados desejados de um arquivo HTML. Neste curso você aprenderá a utilizar o pacote **BeautifulSoup** para realizar esta tarefa.\n",
    "\n",
    "##### Validar\n",
    "\n",
    "Se tivermos feito tudo certo até agora, validar os resultados será uma tarefa simples. Precisamos apenas reproduzir o procedimento descrito até agora para algumas outras páginas de modo verificar se estamos de fato extraindo corretamente tudo o que queremos.\n",
    "* Qualidade da conexão do servidor\n",
    "* Viabilidade do processo nas dimensões:\n",
    "    * tempo\n",
    "    * armazenamento\n",
    "    * complexidade\n",
    "* Padronização do HTML\n",
    "* Exatidão dos resultados obtidos\n",
    "* Tratamento de erros\n",
    "\n",
    "##### Iterar\n",
    "\n",
    "O último passo consiste em colocar o nosso scraper em produção. Na maior parte dos casos isso consiste em encapsular o scraper em uma função que recebe uma série de links e aplica o mesmo procedimento em cada um. Se quisermos aumentar a eficiência desse processo, podemos paralelizar ou distribuir o nosso raspador, além de automatizar o processo de raspagem.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img style=\"width: 400px;\" src=\"https://maxcdn.icons8.com/Share/icon/Dusk_Wired/Household/light_automation1600.png\">\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
